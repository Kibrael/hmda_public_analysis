{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "from lib.data_tools import *\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of public HMDA data tables in PG\n",
    "lar_tables = [\"lar_2004_ffiec\", \"lar_2005_ffiec\", \"lar_2006_ffiec\", \"lar_2007_ffiec\", \"lar_2008_ffiec\", \"lar_2009_ffiec\"\n",
    "         ,\"lar_2010_ffiec\", \"lar_2011_ffiec\", \"lar_2012_ffiec\", \"lar_2013_ffiec\", \"lar_2014_ffiec\", \"lar_2015_ffiec\",\n",
    "         \"lar_2016_ffiec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling metrics for: lar_2004_ffiec\n",
      "pulling metrics for: lar_2005_ffiec\n",
      "pulling metrics for: lar_2006_ffiec\n",
      "pulling metrics for: lar_2007_ffiec\n",
      "pulling metrics for: lar_2008_ffiec\n",
      "pulling metrics for: lar_2009_ffiec\n",
      "pulling metrics for: lar_2010_ffiec\n",
      "pulling metrics for: lar_2011_ffiec\n",
      "pulling metrics for: lar_2012_ffiec\n",
      "pulling metrics for: lar_2013_ffiec\n",
      "pulling metrics for: lar_2014_ffiec\n",
      "pulling metrics for: lar_2015_ffiec\n",
      "pulling metrics for: lar_2016_ffiec\n",
      "pulling metrics for: lar_2004_ffiec\n",
      "pulling metrics for: lar_2005_ffiec\n",
      "pulling metrics for: lar_2006_ffiec\n",
      "pulling metrics for: lar_2007_ffiec\n",
      "pulling metrics for: lar_2008_ffiec\n",
      "pulling metrics for: lar_2009_ffiec\n",
      "pulling metrics for: lar_2010_ffiec\n",
      "pulling metrics for: lar_2011_ffiec\n",
      "pulling metrics for: lar_2012_ffiec\n",
      "pulling metrics for: lar_2013_ffiec\n",
      "pulling metrics for: lar_2014_ffiec\n",
      "pulling metrics for: lar_2015_ffiec\n",
      "pulling metrics for: lar_2016_ffiec\n"
     ]
    }
   ],
   "source": [
    "#Set up filters (where clauses) to build aggregate data \n",
    "#sf = single family, purch = purchase loan, conv = conventional loan \n",
    "#occ = owner occupied, first = first lien\n",
    "sf_purch_conv_occ_first = \"WHERE property_type='1' AND purpose='1' AND loan_type='1' AND occupancy='1' AND lien='1'\"\n",
    "#sf = single family, purch = purchase loan, conv = conventional loan, \n",
    "#occ = owner occupied, junior = junior lien\n",
    "sf_purch_conv_occ_junior = \"WHERE property_type='1' AND purpose='1' AND loan_type='1' AND occupancy='1' AND lien='2'\"\n",
    "\n",
    "sf_purch_conv_occ_first_amt_df = pd.DataFrame(get_lar_stats(\"amount\", lar_tables, \n",
    "                                                            where=sf_purch_conv_occ_first))\n",
    "sf_purch_conv_occ_first_amt_df.to_csv(\"../output/sf_purch_conv_occ_first_amt.csv\", sep=\"|\", index=False)\n",
    "\n",
    "\n",
    "sf_purch_conv_occ_junior_amt_df=pd.DataFrame(get_lar_stats(\"amount\", lar_tables, \n",
    "                                                           where=sf_purch_conv_occ_junior))\n",
    "\n",
    "sf_purch_conv_occ_junior_amt_df.to_csv(\"../output/sf_purch_conv_occ_junior_amt.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulling metrics for: lar_2004_ffiec\n",
      "pulling metrics for: lar_2005_ffiec\n",
      "pulling metrics for: lar_2006_ffiec\n",
      "pulling metrics for: lar_2007_ffiec\n",
      "pulling metrics for: lar_2008_ffiec\n",
      "pulling metrics for: lar_2009_ffiec\n",
      "pulling metrics for: lar_2010_ffiec\n",
      "pulling metrics for: lar_2011_ffiec\n",
      "pulling metrics for: lar_2012_ffiec\n",
      "pulling metrics for: lar_2013_ffiec\n",
      "pulling metrics for: lar_2014_ffiec\n",
      "pulling metrics for: lar_2015_ffiec\n",
      "pulling metrics for: lar_2016_ffiec\n",
      "pulling metrics for: lar_2004_ffiec\n",
      "pulling metrics for: lar_2005_ffiec\n"
     ]
    }
   ],
   "source": [
    "sf_purch_conv_occ_first = \"WHERE property_type='1' AND purpose='1' AND loan_type='1' AND occupancy='1' AND lien='1'\"\n",
    "sf_purch_conv_occ_junior = \"WHERE property_type='1' AND purpose='1' AND loan_type='1' AND occupancy='1' AND lien='2'\"\n",
    "inc_na_where = \" AND income NOT LIKE '%NA%' AND income not like '%na%' \"\n",
    "sf_purch_conv_occ_first_inc_df = pd.DataFrame(get_lar_stats(\"income\", lar_tables, \n",
    "                                                    where=sf_purch_conv_occ_first+inc_na_where))\n",
    "\n",
    "sf_purch_conv_occ_first_inc_df.to_csv(\"../output/sf_purch_conv_occ_first_inc.csv\", sep=\"|\", index=False)\n",
    "\n",
    "sf_purch_conv_occ_junior_inc_df=pd.DataFrame(get_lar_stats(\"income\", lar_tables, \n",
    "                                                   where=sf_purch_conv_occ_junior + inc_na_where))\n",
    "sf_purch_conv_occ_junior_inc_df.to_csv(\"../output/sf_purch_conv_occ_junior_inc.csv\", sep=\"|\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action frequency, percent, cumulative percent\n",
    "cur = connect()\n",
    "def get_action_frequency(table):\n",
    "    sql = \"\"\"\n",
    "    SELECT year, action\n",
    "    ,(ROUND(COUNT(action) *100.0/ (SELECT COUNT(*) FROM {table}) )) AS freq_pct\n",
    "    ,(CASE WHEN action='1' THEN COUNT(action) \n",
    "    WHEN action='2' THEN COUNT(action)  \n",
    "    WHEN action='3' THEN COUNT(action) \n",
    "    WHEN action='4' THEN COUNT(action) \n",
    "    WHEN action='5' THEN COUNT(action) \n",
    "    WHEN action='6' THEN COUNT(action) \n",
    "    WHEN action='7' THEN COUNT(action)  \n",
    "    WHEN action='8' THEN COUNT(action) END) AS action_count\n",
    "    FROM {table}\n",
    "    GROUP BY year, action\n",
    "    ORDER BY action\"\"\".format(table=table)\n",
    "    cur.execute(sql)\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    data_df = pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    return data_df\n",
    "\n",
    "first = True\n",
    "for table in lar_tables:\n",
    "    action_df = get_action_frequency(table)\n",
    "    print(action_df.head())\n",
    "    if first:\n",
    "        first = False\n",
    "        action_freq_df = action_df.copy()\n",
    "    else:\n",
    "        action_freq_df = pd.concat([action_freq_df, action_df])\n",
    "action_freq_df.to_csv(\"../output/action_freq.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Race/Action matrix counts\n",
    "cur=connect()\n",
    "def get_action_race_tab(table):\n",
    "\n",
    "    sql = \"\"\"--CREATE EXTENSION tablefunc;\n",
    "   SELECT * \n",
    "    FROM crosstab( \n",
    "    'SELECT action, race_1, count(race_1)\n",
    "    from {table} group by 1,2 order by 1,2')  \n",
    "    AS final_result(\n",
    "    \"action_type\" varchar, \n",
    "    \"native\" bigint, \"asian\" bigint, \"black\" bigint, \"islander\" bigint, \"white\" bigint, \n",
    "    \"no_info\" bigint,\"NA\" bigint)\"\"\".format(table=table)\n",
    "    cur.execute(sql)\n",
    "    colnames = [desc[0] for desc in cur.description]\n",
    "    data_df = pd.DataFrame(cur.fetchall(), columns=colnames)\n",
    "    return data_df\n",
    "\n",
    "first = True\n",
    "for table in lar_tables:\n",
    "    year = table[4:8]\n",
    "    action_race_df = get_action_race_tab(table)\n",
    "    action_race_df[\"year\"] = year\n",
    "    print(action_race_df.head())\n",
    "    if first:\n",
    "        first = False\n",
    "        action_race_freq_df = action_race_df.copy()\n",
    "    else:\n",
    "        action_race_freq_df = pd.concat([action_race_freq_df, action_race_df])\n",
    "action_race_freq_df.to_csv(\"../output/action_race_freq_df.csv\", sep=\"|\", index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
